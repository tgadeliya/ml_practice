{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language models on the materials of **Sigmorphon 2018 Shared Task** for Russian dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-train-high\n",
    "#!wget https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-dev\n",
    "#!wget https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_infile(infile):\n",
    "    words = []\n",
    "    \n",
    "    with open(infile, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            _, form, *tags = line.split()\n",
    "            if len(tags) == 1:\n",
    "                words.append(form)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9213 917 922\n",
      "валлонскому незаконченным истрёпывав личного серьгам необоснованным тюти заросла идеальна гулкой\n"
     ]
    }
   ],
   "source": [
    "train_words = read_infile(\"russian-train-high\")\n",
    "dev_words = read_infile(\"russian-dev\")\n",
    "test_words = read_infile(\"russian-test\")\n",
    "print(len(train_words), len(dev_words), len(test_words))\n",
    "print(*train_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-27 19:26:00.321 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 49: No load path is set for SimpleVocabulary in 'infer' mode. Using save path instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "vocab = SimpleVocabulary(special_tokens=[\"<PAD>\", \"<BEGIN>\", \"<END>\"], save_path = \"/\")\n",
    "vocab.fit([list(x) for x in train_words])\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import torch\n",
    "\n",
    "class Dataset(TorchDataset):\n",
    "    \n",
    "    \"\"\"Custom data.Dataset compatible with data.DataLoader.\"\"\"\n",
    "    def __init__(self, data, vocab):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "       \n",
    "        source =[self.vocab(\"<BEGIN>\")]\n",
    "        source.extend([self.vocab(x) for x in self.data[index]])\n",
    "        \n",
    "        target = source[1:].copy()\n",
    "        target.append(self.vocab(\"<END>\"))\n",
    "        \n",
    "        return torch.tensor(source, dtype = torch.long), torch.tensor(target, dtype = torch.long)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_words, vocab)\n",
    "dev_dataset = Dataset(dev_words, vocab)\n",
    "test_dataset = Dataset(test_words, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12]) torch.Size([1, 12])\n",
      "torch.Size([1, 12]) torch.Size([1, 12])\n",
      "torch.Size([1, 12]) torch.Size([1, 12])\n",
      "torch.Size([1, 12]) torch.Size([1, 12])\n",
      "torch.Size([1, 12]) torch.Size([1, 12])\n",
      "torch.Size([1, 12]) torch.Size([1, 12])\n",
      "torch.Size([1, 12]) torch.Size([1, 12])\n",
      "torch.Size([1, 12]) torch.Size([1, 12])\n",
      "torch.Size([1, 12]) torch.Size([1, 12])\n",
      "torch.Size([1, 12]) torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=1)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    x, y = next(iter(dataloader)) \n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *In order to create batch we need to stack(vertically) vectors, but we have vectors representing words with different lengths. In this case, it is impossible to create batch without padding shorter words*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate function for padding to create batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(vec, length, dim, pad_symbol):\n",
    "    num_pad  = length - vec.shape[dim]\n",
    "    pad = torch.fill_(torch.empty(num_pad, dtype = torch.long), pad_symbol)\n",
    "    return torch.cat((vec, pad), dim=0)#.unsqueeze(0)\n",
    "\n",
    "class Padder:\n",
    "    \n",
    "    def __init__(self, dim=0, pad_symbol=2):\n",
    "        self.dim = dim\n",
    "        self.pad_symbol = pad_symbol\n",
    "        self.x_len, self.y_len = 0, 0\n",
    "        \n",
    "    def apply_pad(self, x, y):\n",
    "        x = pad_tensor(x, self.x_len, self.dim , self.pad_symbol) \n",
    "        y = pad_tensor(y, self.y_len, self.dim , self.pad_symbol)\n",
    "        return (x,y)\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \n",
    "        for x,y in batch:\n",
    "            self.x_len, self.y_len = max(self.x_len, len(x)), max(self.y_len, len(y))   \n",
    "       \n",
    "        \n",
    "        batch = list(map(lambda x: self.apply_pad(x[0], x[1]), batch))\n",
    "        \n",
    "        \n",
    "        xs = tuple(map(lambda x: x[0], batch))\n",
    "        ys = tuple(map(lambda x: x[1], batch))\n",
    "        \n",
    "        xs = torch.stack(xs, dim=0)\n",
    "        ys = torch.stack(ys, dim=0)\n",
    "        \n",
    "        return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19]) torch.Size([64, 19])\n",
      "torch.Size([64, 19]) torch.Size([64, 19])\n",
      "torch.Size([64, 19]) torch.Size([64, 19])\n",
      "torch.Size([64, 21]) torch.Size([64, 21])\n",
      "torch.Size([64, 21]) torch.Size([64, 21])\n",
      "torch.Size([64, 21]) torch.Size([64, 21])\n",
      "torch.Size([64, 21]) torch.Size([64, 21])\n",
      "torch.Size([64, 21]) torch.Size([64, 21])\n",
      "torch.Size([64, 21]) torch.Size([64, 21])\n",
      "torch.Size([64, 21]) torch.Size([64, 21])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_dataset,batch_size=64, collate_fn=Padder(dim=0), shuffle=True)\n",
    "val_dataloader = DataLoader(dev_dataset, batch_size=64, collate_fn=Padder(dim=0), shuffle=False)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    x, y = next(iter(dataloader)) \n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-based language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model description: \n",
    "\n",
    "1. **Embedding** layer that transforms input symbols into vectors.\n",
    "2. An **RNN** layer that outputs a sequence of hidden states (I am using GRU).\n",
    "3. A **Linear** layer with *softmax* activation that produces the output distribution for each symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "class RNNLM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embeddings_dim, hidden_size):\n",
    "        super(RNNLM, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, embeddings_dim)\n",
    "        self.gru = nn.GRU(embeddings_dim, hidden_size,batch_first = True)\n",
    "        self.lin = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "        init.kaiming_normal_(self.lin.weight) \n",
    "        init.kaiming_normal_(self.emb.weight) \n",
    "        #GRU Initialization\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs, hidden=None): # [batch_size, seq_len]\n",
    "        x_emb = self.emb.forward(inputs) # [batch_size,seq_len, voc_size]\n",
    "        x_rnn, ht = self.gru.forward(x_emb) # [batch_size, seq_len, hi], [hidden_size, seq_len]\n",
    "        x_lin = self.lin.forward(x_rnn)\n",
    "        prob = self.softmax(x_lin)\n",
    "        return prob, ht\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_on_batch(model, criterion, x, y):\n",
    "    pred, ht = model(x)\n",
    "    loss = criterion(pred.permute([0,2,1]), y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, criterion, x, y, optimizer):\n",
    "    \n",
    "    loss = torch.mean(validate_on_batch(model, criterion, x, y))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_avg = loss.item()\n",
    "    \n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(model, dataloader, val_dataloader, optimizer, scheduler, criterion, epochs):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    iter_b = dataloader.__len__()\n",
    "    \n",
    "    model.to(device = DEVICE)\n",
    "    for e in range(1, epochs+1):\n",
    "        model.train() \n",
    "    \n",
    "        t_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device = DEVICE), y.to(device = DEVICE)\n",
    "    \n",
    "            loss_avgb = train_on_batch(model, criterion, x, y, optimizer) # average on batch\n",
    "            t_loss += loss_avgb\n",
    "    \n",
    "        t_loss_avg = t_loss/iter_b # average on one epoch\n",
    "        \n",
    "        train_losses.append(t_loss_avg) \n",
    "        print(\"[{}] loss: {:.3f} \".format(e, t_loss_avg))\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        val_loss = validate(model, criterion, val_dataloader)\n",
    "        val_losses.append(val_loss)\n",
    "    return val_losses\n",
    "\n",
    "def validate(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    iter_b = dataloader.__len__()\n",
    "    v_lossb_avg = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (x,y) in dataloader:\n",
    "            v_lossb_avg += torch.mean(validate_on_batch(model, criterion, x, y))\n",
    "\n",
    "    return v_lossb_avg/iter_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model parameters\n",
    "vocab_size = len(vocab)\n",
    "embeddings_dim = 20\n",
    "hidden_size = 30\n",
    "\n",
    "model = RNNLM(vocab_size, embeddings_dim, hidden_size)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.03)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 2, gamma = 0.01)\n",
    "criterion = nn.NLLLoss(ignore_index=vocab['<PAD>'], reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]loss: 1.020 \n",
      "[2]loss: 0.869 \n",
      "[3]loss: 0.845 \n",
      "[4]loss: 0.838 \n",
      "[5]loss: 0.836 \n"
     ]
    }
   ],
   "source": [
    "loss = train_eval(model, dataloader, val_dataloader, optimizer, scheduler, criterion, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)\n",
    "plt.title(\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using language model to generate words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Write a function **predict_on_batch** that outputs letter probabilities of all words in the batch.\n",
    "- Calculate the letter probabilities for all words in the test dataset. Print them for 20 last words. Do not forget to disable shuffling in the *DataLoader*.\n",
    "- Write a function that generates a single word (sequence of indexes) given the model. Do not forget about the hidden state! Be careful about start and end symbol indexes. Use ``torch.multinomial`` for sampling.\n",
    "- Use generate to sample 20 pseudowords. Do not forget to transform indexes to letters.\n",
    "- Write a batched version of the generation function.\n",
    "- improve the perplexity of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_batch(model, x, vocab):\n",
    "    model.eval()\n",
    "    out, hidden = model(x)\n",
    "    pred = torch.exp(out)\n",
    "     \n",
    "    return pred\n",
    "\n",
    "\n",
    "### Indexing output by y true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['<BEGIN>', 'х', 'р', ..., '<END>', '<END>', '<END>'],\n",
       "       ['<BEGIN>', 'н', 'а', ..., '<END>', '<END>', '<END>'],\n",
       "       ['<BEGIN>', 'р', 'а', ..., '<END>', '<END>', '<END>'],\n",
       "       ...,\n",
       "       ['<BEGIN>', 'м', 'у', ..., '<END>', '<END>', '<END>'],\n",
       "       ['<BEGIN>', 'с', 'о', ..., '<END>', '<END>', '<END>'],\n",
       "       ['<BEGIN>', 'р', 'а', ..., '<END>', '<END>', '<END>']], dtype='<U7')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(lambda x: vocab[x])(x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_prob(model, dataloader, vocab):\n",
    "    with torch.no_grad():\n",
    "        words_probs = []\n",
    "        for x, _ in dataloader:\n",
    "            words_probs.append(predict_on_batch(model, x, vocab))\n",
    "        return words_probs\n",
    "\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "word_probabilities = letter_prob(model, test_loader, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_generate(model, index, last_hidden):\n",
    "    x = torch.tensor(index, dtype=torch.long).reshape(1,1)\n",
    "    distribution, hidden = model.forward(x,hidden = last_hidden)\n",
    "    return distribution, hidden\n",
    "\n",
    "def generate_word(model, vocab, max_length=20, start_index=1, end_index=2):\n",
    "    word = ''\n",
    "    \n",
    "    hidden_state = None\n",
    "    last_symbol = np.random.randint(3, 52)\n",
    "    \n",
    "    length = 0\n",
    "    while(last_symbol != end_index and length <= max_length):\n",
    "        word += vocab[last_symbol]\n",
    "        distribution, hidden_state = aux_generate(model, last_symbol, hidden_state)\n",
    "        length += 1\n",
    "        last_symbol = int(torch.multinomial(torch.exp(distribution), 1))\n",
    "        \n",
    "    return word\n",
    "\n",
    "def generate(model, max_length=20, start_index=1, end_index=2):\n",
    "    return generate_word(model, vocab, max_length=20, start_index=1, end_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word(model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(model, batch_size, max_length = 20, start_index=1, end_index=2):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD PERPLEXITY ON VALIDATION\n",
    "# DROPOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION\n",
    "# - Why not hot-encoded\n",
    "# - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
